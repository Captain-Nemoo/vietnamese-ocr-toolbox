{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1153f29-63a7-4fcf-907c-a276b56c4351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun  6 00:21:24 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.80       Driver Version: 460.80       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1050    Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   66C    P0    N/A /  N/A |    276MiB /  4042MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1129      G   /usr/lib/xorg/Xorg                147MiB |\n",
      "|    0   N/A  N/A      1447      G   /usr/bin/gnome-shell               27MiB |\n",
      "|    0   N/A  N/A      2566      G   ...AAAAAAAAA= --shared-files       46MiB |\n",
      "|    0   N/A  N/A      3418      G   ...AAAAAAAAA= --shared-files       52MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a96ec688-ef7e-4e10-be60-4481f40924a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e2cb43-3a0c-45a0-86cb-46fc221b4df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'dataset': { 'num_folds': None,\n",
      "               'train': { 'args': { 'csv_path': 'data/splitted_train_val/train.csv',\n",
      "                                    'is_train': True,\n",
      "                                    'max_len': 314,\n",
      "                                    'pretrained_model': 'bert-base-uncased'},\n",
      "                          'loader': { 'args': { 'batch_size': 2,\n",
      "                                                'drop_last': False,\n",
      "                                                'num_workers': 4,\n",
      "                                                'pin_memory': True,\n",
      "                                                'shuffle': True},\n",
      "                                      'name': 'DataLoader'},\n",
      "                          'name': 'ReadabilityDataset'},\n",
      "               'val': { 'args': { 'csv_path': 'data/splitted_train_val/val.csv',\n",
      "                                  'is_train': True,\n",
      "                                  'max_len': 314,\n",
      "                                  'pretrained_model': 'bert-base-uncased'},\n",
      "                        'loader': { 'args': { 'batch_size': 2,\n",
      "                                              'num_workers': 4,\n",
      "                                              'pin_memory': True,\n",
      "                                              'shuffle': False},\n",
      "                                    'name': 'DataLoader'},\n",
      "                        'name': 'ReadabilityDataset'}},\n",
      "  'debug': False,\n",
      "  'fp16': False,\n",
      "  'fp16_opt_level': 'O2',\n",
      "  'gpus': '0',\n",
      "  'id': 'bert-base-single-fold',\n",
      "  'loss': {'args': None, 'name': 'RMSELoss'},\n",
      "  'metric': [{'args': None, 'name': 'RMSE_metric'}],\n",
      "  'model': { 'args': { 'max_pool': False,\n",
      "                       'pretrained_model': 'bert-base-uncased',\n",
      "                       'use_dropout': True},\n",
      "             'name': 'AutoModel'},\n",
      "  'optimizer': {'args': {'lr': 2e-05, 'weight_decay': 0.01}, 'name': 'AdamW'},\n",
      "  'pretrained': None,\n",
      "  'scheduler': { 'args': {'num_training_steps': 5680, 'num_warmup_steps': 340},\n",
      "                 'name': 'get_linear_schedule_with_warmup'},\n",
      "  'trainer': {'log_step': 1, 'nepochs': 20, 'val_freq': 30, 'val_step': 1},\n",
      "  'verbose': False}\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch 0 training........\n",
      "At step 29/1134\n",
      "Evaluating........\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train_base.py\", line 164, in <module>\n",
      "    train(config)\n",
      "  File \"train_base.py\", line 98, in train\n",
      "    trainer.train(train_dataloader=train_dataloader, val_dataloader=val_dataloader)\n",
      "  File \"./libs/workers/trainer.py\", line 213, in train\n",
      "    self.train_epoch(epoch=epoch, dataloader=train_dataloader, val_dataloader=val_dataloader)\n",
      "  File \"./libs/workers/trainer.py\", line 150, in train_epoch\n",
      "    self.val_epoch(epoch, dataloader=val_dataloader)\n",
      "  File \"/home/kvu/commonlit-readability-prize/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"./libs/workers/trainer.py\", line 185, in val_epoch\n",
      "    running_loss.add(loss.item())\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 train_base.py --config configs/single-fold-models/bert-base.yaml --gpus 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46673e6f-328c-445e-8d3e-e0890947362e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
